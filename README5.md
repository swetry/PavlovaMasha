Аналитическая часть практической работы №5

1. Сортировка выбором
## Работа алгоритма
Этот скрипт реализует базовую версию алгоритма сортировки выбором (`Selection Sort`). Алгоритм состоит из следующих шагов:
1. Для каждого элемента массива мы ищем наименьший элемент среди всех последующих позиций.
2. Найденный минимальный элемент меняется местами с текущим рассматриваемым элементом.
3. Этот процесс повторяется до тех пор, пока весь массив не окажется отсортирован.

## Оценка производительности (сложность)
Оценивать производительность алгоритмов принято по **наихудшему случаю**. Рассмотрим временную сложность для алгоритма сортировки выбором:
- ### Пространственная сложность: **O(1)**.
  Дополнительная память используется лишь для хранения временных переменных (например, индекса минимума и временного буфера для обмена элементами). Объем дополнительной памяти не зависит от размера входного массива.
- ### Временная сложность: **O(N²)**.
  *Внешний цикл* выполняется N−1 раз (N — длина массива), а внутренний цикл выполняется N-i раз на каждой итерации внешнего цикла. Следовательно, количество сравнений примерно равно сумме первых N натуральных чисел минус единицу:
$$\text{Количество операций сравнения}: \sum_{i=0}^{N-1}(N-i)=N^2-N+O(N)\approx\frac{N^2}{2}-O(N)=\Theta(N^2)$$
Таким образом, итоговая временная сложность составляет **O(N²)** даже в лучшем и среднем случаях, потому что независимо от начального порядка элементов алгоритм всегда требует полного прохода внутренним циклом для каждого шага внешнего цикла. Это означает, что скорость выполнения программы существенно снижается при увеличении размера входных данных.

## Итоговая оценка эффективности:
- **Пространственная эффективность**: **O(1)** — дополнительная память практически отсутствует.
- **Время выполнения**: **O(N²)** — квадратичное замедление по мере роста количества элементов.
Следовательно, сортировка выбором является простым и понятным способом сортировки, но крайне неэффективным для больших объемов данных. Она применяется преимущественно там, где важна простота реализации и объем обрабатываемых данных невелик.

2. Реализация сортировки обменом (метод пузырька) на Java
## Описание алгоритма
Метод пузырьковой сортировки (`Bubble Sort`) работает следующим образом:
1. **Проходы по массиву:** Во внешнем цикле осуществляется перебор всех элементов массива.
2. **Сравнения соседних элементов:** Внутри основного цикла элементы последовательно сравниваются попарно, начиная с первой пары.
3. **Перестановка элементов:** Если обнаруживается, что текущий элемент больше следующего, они меняются местами ("взлетают вверх").
4. **Досрочный выход:** Когда на каком-то этапе перестановок не произошло, это означает, что массив уже отсортирован, и дальнейшие проверки прекращаются.
## Оценка производительности (сложность)
### Пространственная сложность: **O(1)**
Дополнительная память потребляется только для одной временной переменной (`temp`), используемой для обмена значениями элементов. Размер дополнительного пространства не зависит от объема входных данных.
### Временная сложность: **O(n²)**
Алгоритм совершает полное сравнение каждого элемента с каждым другим, выполняя вложенный цикл дважды по всему массиву. Даже несмотря на оптимизацию досрочного выхода, в худшем случае число сравнений остается приблизительно равным половине квадрата длины массива:
$$ \frac{n(n-1)}{2}\approx O(n^{2}) $$
Поэтому временная сложность в худшем и среднем случаях остаётся **O(n²)**.
## Итоговая оценка эффективности:
- **Пространственная эффективность**: **O(1)** — минимальная потребность в дополнительном пространстве.
- **Время выполнения**: **O(n²)** — низкая производительность при работе с большими наборами данных.
Хотя сортировка пузырьком проста в понимании и реализации, её использование целесообразно только для небольших массивов или учебных целей.3.Сортировка вставками

3. Реализация сортировки вставками на Python

## Описание алгоритма
Алгоритм сортировки вставками (`Insertion Sort`) основывается на постепенном расширении уже отсортированного участка массива. Основные шаги:
1. **Выбираем первый несортированный элемент.** Мы начинаем со второго элемента массива (так как первый считается автоматически отсортированным).
2. **Ищем позицию для вставки выбранного элемента.** Просматриваем предыдущие элементы, двигаясь назад, пока не найдем подходящую позицию для текущего элемента.
3. **Производим сдвиг элементов вправо**, создавая свободное место для вставки.
4. **Помещаем выбранный элемент на найденную позицию.**
Эти шаги повторяются до полной сортировки всего массива.
## Оценка производительности (сложность)
### Пространственная сложность: **O(1)**
Алгоритм сортировки вставками не требует дополнительного пространства, кроме одной временной переменной (`key`), хранящей текущий элемент. Поэтому пространственная сложность постоянна и равна **O(1)**.
### Временная сложность: **O(n²)**
Основная вычислительная нагрузка связана с перемещением элементов внутри внутреннего цикла. Хоть среднее и лучшее случаи (уже отсортированный массив) имеют меньшую сложность, в худшем случае (обратный порядок элементов) потребуется выполнить около $\frac{n(n-1)}{2}$ сравнений и присваиваний, что соответствует сложности **O(n²)**.
Однако, важно отметить, что сортировка вставками обладает преимуществом перед некоторыми другими простыми сортировками (например, пузырьковая), поскольку в лучших случаях (почти отсортированный массив) может выполняться значительно быстрее.

## Итоговая оценка эффективности:
- **Пространственная эффективность**: **O(1)** — минимальное потребление памяти.
- **Время выполнения**: **O(n²)** — средняя и худшая временные характеристики.
Сортировка вставками хорошо подходит для малых массивов или почти отсортированных данных, обеспечивая достаточно высокую производительность в таких ситуациях. Однако для больших объёмов данных рекомендуется применять более эффективные методы типа быстрой сортировки или сортировки слиянием.

4. Сортировка слиянием
# Реализация сортировки слиянием на Java
## Описание алгоритма
Алгоритм сортировки слиянием (`Merge Sort`) основан на парадигме "разделяй и властвуй". Его работа включает два основных этапа:
1. **Разделение** (*Divide*) — Исходный массив делится на две равные части, каждая из которых снова рекурсивно делится пополам, пока не останутся отдельные элементы.
2. **Объединение** (*Conquer*) — Получившиеся маленькие упорядоченные подмассивы последовательно сливаются друг с другом, образуя большие отсортированные последовательности, пока не получится единый отсортированный массив.
## Оценка производительности (сложность)
### Пространственная сложность: **O(n)**
Для работы алгоритма необходим дополнительный массив размером `n`, куда временно сохраняются промежуточные результаты сортировки. Таким образом, пространство пропорционально размеру входного массива.
### Временная сложность: **O(n log n)**
Временная сложность определяется двумя основными этапами:
- **Разбиение массива:** Каждое деление массива занимает O(log n) проходов.
- **Обработка слияния:** Каждая операция слияния проходит по каждому элементу массива ровно один раз, следовательно, имеет линейную сложность O(n).
Поскольку оба процесса выполняются одновременно, общая временная сложность равна произведению этих этапов: **O(n log n)**. Это делает сортировку слиянием гораздо эффективнее для больших массивов по сравнению с простыми методами вроде сортировки выбором или пузырьковой сортировкой.

## Итоговая оценка эффективности:
- **Пространственная эффективность**: **O(n)** — дополнительное пространство пропорционально объему входных данных.
- **Время выполнения**: **O(n log n)** — эффективная производительность для любых размеров массивов.
Таким образом, сортировка слиянием отлично подходит для обработки больших объемов данных благодаря своей стабильности и гарантированной средней и худшей временной сложности.

5. Сортировка Шелла (Shell Sort)
Работа алгоритма
Алгоритм сортировки Шелла представляет собой усовершенствованную версию сортировки вставками. Основная идея заключается в том, чтобы сначала сравнивать элементы, находящиеся далеко друг от друга, уменьшая шаг (gap) с каждым новым этапом. Благодаря этому предварительная грубая сортировка значительно ускоряет финальный этап.
Основные этапы алгоритма:
Определяется шаг (gap), изначально составляющий половину размера массива.
Элементы массива сортируются группами с выбранным шагом.
Затем шаг делится пополам, и вновь производится сортировка.
Процесс продолжается до тех пор, пока шаг не достигнет единицы, после чего выполняется обычная сортировка вставками.
Такой подход позволяет быстрее достигать нужной последовательности, особенно для больших массивов.
Оценка производительности (сложность)
При оценке производительности важным аспектом является учет двух ключевых факторов: пространственная и временная сложность.
Пространственная сложность: O(1)
Алгоритм работает in-place, то есть требует минимальной дополнительной памяти только для временной переменной для обмена элементов. Эта величина фиксирована и не зависит от размера входных данных.
Временная сложность: O(N log N) → O(N²)
Хотя средняя и лучшая временная сложность ближе к O(N log N), на практике поведение часто приближено к O(N²) в зависимости от выбора шага и начальной конфигурации массива. Чем лучше выбор начальных интервалов, тем эффективнее выполнение. Однако на плохих шагах и плохо отсортированном массиве сложность стремится к квадратичной.
Так как внутренние циклы перебора требуют многократных проверок и перестановок, среднее время исполнения возрастает быстро при росте объема данных.
Итоговая оценка эффективности:
Пространственная эффективность: O(1) — низкая потребность в дополнительной памяти.
Время выполнения: O(N log N) → O(N²) — средняя производительность близка к оптимальной, но легко деградирует до плохой (квадратичной) при неудачном выборе шага.
Заключение
Сортировка Шелла — хороший компромисс между производительностью и простотой реализации. Особенно эффективна на средних объёмах данных благодаря быстрому улучшению начальной расстановки элементов перед окончательной сортировкой. Рекомендуется применять её тогда, когда важен баланс между скоростью и потреблением ресурсов.

6. Быстрая сортировка (Quicksort)
Работа алгоритма
Быстрая сортировка (quick sort) — рекурсивный алгоритм сортировки, который основан на принципе "разделяй и властвуй":
Из массива выбирается произвольный элемент, называемый опорным (pivot).
Остальные элементы массива распределяются вокруг опорного элемента таким образом, что все элементы меньше опорного оказываются слева, а все элементы больше — справа.
Эти два новых подмассива (левый и правый) снова рекурсивно сортируются аналогичным образом.
Как только оба подмассива будут отсортированы, объединяются все три группы (меньше опорного, равные опорному, больше опорного), формируя полностью отсортированную последовательность.
Эта стратегия позволяет достичь хорошей средней производительности, делая алгоритм одним из наиболее эффективных методов сортировки.
Оценка производительности (сложность)
Оценим производительность быстрой сортировки:
Пространственная сложность: O(log N) → O(N)
Основная операция алгоритма осуществляется в стеке вызовов функций, глубина которого определяется глубиной рекурсии. В лучших случаях эта глубина соответствует высоте дерева бинарного разделения, то есть log₂N. Но в худшем случае (если выбрать неверный опорный элемент), дерево превращается в линейное, и пространство занимает O(N).
Кроме того, каждый рекурсивный вызов создаёт временные списки, что добавляет небольшие накладные расходы.
Временная сложность: O(N log N) → O(N²)
Средняя производительность алгоритма достигает O(N log N), так как оптимальное разделение массива уменьшает глубину рекурсии. Тем не менее, если выбирать неоптимальные опорные элементы (например, минимальные или максимальные), возможны ситуации, когда деление будет неравномерным, приводящим к худшей производительности — O(N²). Чтобы избежать подобного сценария, применяются разные стратегии выбора опорного элемента (например, случайный выбор или использование среднего значения трёх элементов).
Итоговая оценка эффективности:
Пространственная эффективность: O(log N) → O(N) — оптимальное потребление пространства возможно при удачной рекурсии, но потенциально увеличивается до O(N) в худшем сценарии.
Время выполнения: O(N log N) → O(N²) — среднеэффективный алгоритм, но уязвимый к выбору плохого опорного элемента, что снижает его производительность до квадратичного уровня.
Заключение
Быстрая сортировка — чрезвычайно эффективный алгоритм для большинства практических задач, обеспечивая высокую среднюю производительность. Её рекомендуют использовать везде, кроме случаев, когда гарантированная квадратичная сложность недопустима (например, при наличии заранее отсортированного массива).

7.Пирамидальная сортировка (Heapsort)
Работа алгоритма
Пирамидальная сортировка основана на структуре данных **бинарная куча** (*binary heap*) и включает две ключевые фазы:
1. **Фаза построения кучи**:
   - Сначала входной массив преобразуется в **max-кучу** (heapify). Max-куча — это структура, в которой родительские узлы всегда больше своих потомков.
   - Структура строится путем перемещения элементов снизу-вверх и восстановления свойств кучи с использованием процедуры heapify.
2. **Фаза извлечения корней**:
   - Далее происходит последовательное удаление корней (максимальных элементов) из кучи и помещение их в конце массива.
   - Каждое удаление сопровождается восстановлением структуры кучи путём повторного вызова heapify.
Таким образом, после каждой итерации максимальная вершина поднимается на свою правильную позицию, и оставшиеся элементы продолжают формироваться в кучу.
Оценка производительности (сложность)
При анализе производительности важной частью являются показатели пространственной и временной сложности.
##### Пространственная сложность: **O(1)**
Алгоритм осуществляет все манипуляции над существующими элементами массива и не требует дополнительного пространства. Максимально используемая дополнительная память ограничивается несколькими временными переменными, такими как индексы и буфер для обмена. Общий объем дополнительной памяти остаётся постоянным вне зависимости от размера входных данных.
##### Временная сложность: **O(N log N)**
Временная сложность вычисляется исходя из двух фаз:
- **Построение кучи**: занимает O(N), так как каждый узел рассматривается один раз, и каждое движение в куче происходит максимум за log N шагов.
- **Удаление корней**: каждая операция удаления и восстановление кучи занимает O(log N), и такая операция повторяется N раз.
Общее время выполнения получается:$$O(N)+O(N\log N)=O(N\log N)$$ Таким образом, общий порядок вычислительной сложности пирамидальной сортировки стабильно сохраняется на уровне **O(N log N)** в любом случае (лучшем, среднем и худшем).
#### Итоговая оценка эффективности:
- **Пространственная эффективность**: **O(1)** — минимальное дополнительное пространство.
- **Время выполнения**: **O(N log N)** — стабильная производительность даже в худшем случае.
Заключение: Пирамидальная сортировка демонстрирует отличную устойчивость по отношению к различным конфигурациям данных и обеспечивает стабильную производительность, что делает её предпочтительным вариантом для многих приложений, где требуется гарантированно быстрая сортировка большого объема данных.

8. Последовательный поиск (Sequential Search)
Работа алгоритма
Последовательный поиск — простой алгоритм, предназначенный для нахождения заданного элемента в списке или массиве. Суть метода заключается в следующем:
1. Мы проходим по каждому элементу массива, начиная с первого.
2. Если текущий элемент совпадает с искомым, сразу же возвращается его позиция (индекс).
3. Если ни один элемент не совпадёт с искомым, после проверки всех элементов возвращается признак неуспешного поиска (обычно None или False).
Метод полезен своей простотой и отсутствием требований к порядку расположения элементов в массиве.
Оценка производительности (сложность)
Анализируя производительность последовательного поиска, рассмотрим два важных аспекта: пространственную и временную сложность.
##### Пространственная сложность: **O(1)**
Поскольку алгоритм производит только проверку текущих элементов и не создает никаких дополнительных структур данных, пространственная сложность остается постоянной и равной **O(1)**. То есть потребляемая память не зависит от размера входного массива.
##### Временная сложность: **O(N)**
- **Лучшее время выполнения**: O(1) — если искомый элемент находится первым в массиве.
- **Худшее время выполнения**: O(N) — если искомого элемента нет вообще или он расположен последним.
- **Среднее время выполнения**: O(N/2) ≈ O(N) — среднее время поиска также зависит от общего количества элементов.
Суммируя, средняя и худшая сложность составляют **O(N)**, что отражает тот факт, что в большинстве случаев алгоритм вынужден проверять значительное количество элементов массива.
Итоговая оценка эффективности:
- **Пространственная эффективность**: **O(1)** — отсутствие потребности в дополнительной памяти.
- **Время выполнения**: **O(N)** — прямо пропорциональный росту размера массива.
Заключение: Последовательный поиск удобен своей простотой и универсальностью, позволяя искать элементы в несортированных списках. Однако он теряет эффективность при большом объеме данных, поскольку приходится проверять большинство элементов массива для достижения результата.

9. Бинарный поиск (Binary Search)
Работа алгоритма
Бинарный поиск — это эффективный алгоритм поиска элемента в отсортированном массиве. Основные шаги алгоритма:
1. Определение границ поиска: вначале весь массив считается областью поиска.
2. Выбор центральной точки (среднего элемента) в диапазоне поиска.
3. Сравнение центрального элемента с искомым:
   - Если центральный элемент равен искомому, поиск успешен, и возвращается его индекс.
   - Если центральный элемент меньше искомого, дальнейший поиск проводится в правой половине массива.
   - Если центральный элемент больше искомого, поиск продолжается в левой половине.
4. Повторение процесса деления области поиска пополам до тех пор, пока искомый элемент не будет найден либо область поиска не сократится до нуля.
Бинарный поиск обладает преимуществом по скорости за счёт быстрого сокращения области поиска на каждом этапе.
 Оценка производительности (сложность)
Рассмотрим характеристики производительности бинарного поиска:
	Пространственная сложность: **O(1)**
Алгоритм не требует дополнительной памяти для своего функционирования, кроме небольшого количества переменных для хранения индексов границ поиска и промежуточных результатов. Поэтому пространственная сложность постоянная и равна **O(1)**.
Временная сложность: **O(log N)**
Каждый шаг алгоритма делит область поиска пополам, следовательно, максимальное количество шагов равно количеству двоичных разрядов числа N (размер массива). Такое сокращение области поиска гарантирует быстрое достижение цели даже при значительных размерах массива.
Формула оценки временной сложности выглядит так:
$$T(n) = O(\log_2{n}) = O(\log{n})$$  Это показывает, что алгоритм имеет хорошую масштабируемость и хорошо справляется с большим объемом данных.

#### Итоговая оценка эффективности:
- **Пространственная эффективность**: **O(1)** — неизменное потребление памяти.
- **Время выполнения**: **O(log N)** — экспоненциально быстрый рост производительности при увеличении объема данных.
Заключение
Бинарный поиск является эффективным инструментом для работы с отсортированными массивами, предлагая высокое быстродействие и низкую нагрузку на память. Он идеально подходит для ситуаций, когда нужно обеспечить быстрый доступ к данным в большом упорядоченном наборе.

10. Интерполирующий поиск (Interpolation Search)
#### Работа алгоритма
Интерполирующий поиск — это разновидность бинарного поиска, специально предназначенная для равномерно распределённых отсортированных массивов. Ключевая особенность алгоритма заключается в том, что он пытается предсказать местоположение искомого элемента на основе интервала значений массива.
Процесс поиска происходит следующим образом:
1. Определяются границы поиска (начало и конец массива).
2. Используя формулы, основанные на соотношении между текущими граничными значениями и целью поиска, вычисляется вероятная позиция искомого элемента.
3. Если предположение верно, поиск завершён успешно.
4. Если искомый элемент меньше ожидаемой позиции, обновляются верхние границы поиска.
5. Если искомый элемент больше ожидаемой позиции, обновляются нижние границы поиска.
6. Поиск продолжается до момента нахождения элемента или исчерпания диапазона поиска.
Интерполирующий поиск оказывается особенно быстрым, когда распределение элементов равномерное.
#### Оценка производительности (сложность)
Оценим производительность интерполирующего поиска:
##### Пространственная сложность: **O(1)**
Алгоритм не требует дополнительной памяти для хранения временных данных, кроме нескольких переменных для управления границами поиска и расчёта положения. Поэтому пространственная сложность постоянна и равна **O(1)**.
##### Временная сложность: **O(log log N) → O(N)**
Теоретически, в благоприятных ситуациях (при равномерном распределении данных) время выполнения близко к **O(log log N)**, что намного быстрее обычного бинарного поиска. Однако, если распределение элементов хаотическое или неравномерное, временная сложность падает до **O(N)**, превращая алгоритм в простую линейную процедуру.
Оптимальная ситуация возникает именно при равномерном распределении, когда ожидаемая точка попадания быстро приближается к нужному месту.
 Итоговая оценка эффективности:
- **Пространственная эффективность**: **O(1)** — постоянное потребление памяти.
- **Время выполнения**: **O(log log N) → O(N)** — потенциальная сверхбыстрота в хороших условиях, ухудшение до линейного поведения в неблагоприятных.
Заключение
Интерполирующий поиск особенно хорош для больших массивов с равномерным распределением данных, демонстрируя превосходную производительность по сравнению с обычными методами поиска. Однако в случае нерегулярного распределения данных он уступает традиционным решениям вроде бинарного поиска.

11. Фибоначчи-поиск (Fibonacci Search)
#### Работа алгоритма
Фибоначчи-поиск — это особый вид поиска в отсортированном массиве, использующий ряд чисел Фибоначчи для эффективного ограничения области поиска. Вместо деления массива на две равные половины, как в бинарном поиске, фибоначчи-поиск выбирает позиции, основываясь на числах Фибоначчи, что даёт уникальное преимущество при определённом характере распределения данных.
Основной принцип работы алгоритма следующий:
1. Определяется наименьшее число Фибоначчи, превышающее или равное длине массива.
2. Используется данное число для расчёта индекса, по которому производится сравнение.
3. Если искомый элемент больше текущего, граница поиска смещается вправо, и следующая попытка производится на основании предыдущего числа Фибоначчи.
4. Если искомый элемент меньше текущего, область поиска сужается слева.
5. Процесс продолжается до обнаружения элемента или исчерпания вариантов поиска.
Использование чисел Фибоначчи позволяет уменьшать размеры областей поиска непропорционально и обеспечивать высокие темпы уменьшения диапазонов поиска.
#### Оценка производительности (сложность)
Рассмотрим ключевые аспекты производительности фибоначчи-поиска:
##### Пространственная сложность: **O(1)**
Алгоритм использует минимальное количество дополнительной памяти для хранения парных значений (текущего индекса, чисел Фибоначчи и других переменных), не зависящих от размера входного массива. Таким образом, пространственная сложность константа и равна **O(1)**.
##### Временная сложность: **O(log N)**
Каждая итерация фибоначчи-поиска уменьшает размер области поиска согласно свойствам чисел Фибоначчи, обеспечивая уменьшение масштаба примерно на коэффициент золотого сечения ($\phi$). Среднее количество шагов пропорционально логарифму длины массива:
$$T(n) = O(\log_{\phi}{(n)}) \approx O(\log{(n)})$$
Тем не менее, в особых случаях (неравномерное распределение элементов или специфический порядок) производительность может ухудшиться до **O(N)**.
#### Итоговая оценка эффективности:
- **Пространственная эффективность**: **O(1)** — низкий уровень потребления памяти.
- **Время выполнения**: **O(log N)** — хорошая производительность при регулярном распределении данных, иногда хуже при специальных паттернах.
	Заключение: Фибоначчи-поиск является эффективной альтернативой обычным методам поиска, обеспечивающей быстрые результаты в стандартных ситуациях. Однако, как и любые специализированные методы, он чувствителен к особенностям распределения данных и способен демонстрировать снижение производительности при неблагоприятном расположении элементов.
