Анализ алгоритма: Сортировка выбором (Selection Sort)
Определение:
Сортировка выбором (Selection Sort) — это алгоритм, который разделяет массив на две части: отсортированную и неотсортированную. На каждом шаге он находит минимальный элемент в неотсортированной части и меняет его местами с первым элементом этой части.
Анализ:
Алгоритм находит минимальный элемент в неотсортированной части массива и меняет его местами с первым элементом в неотсортированной части.
Внешний цикл for выполняется n-1 раз.
Внутренний цикл for в худшем случае выполняется n-1, затем n-2, ..., раз за каждый проход внешнего цикла.
Общее количество сравнений примерно равно n*(n-1)/2.
Временная сложность: O(n²)
Почему O(n²): Два вложенных цикла, где каждый из них в среднем или худшем случае зависит от n. Внутренний цикл может выполняться до n раз для каждого из n итераций внешнего цикла, что приводит к квадратичной зависимости.
Результат программы на JAVA:
	входные данные:{64, 25, 12, 22, 11}
	выходные данные:{11, 12, 22, 25, 64}
Заключение: сортировка выбором является простым и понятным способом сортировки, но крайне неэффективным для больших объемов данных. Она применяется преимущественно там, где важна простота реализации и объем обрабатываемых данных невелик.
Анализ алгоритма: Сортировка обменом (пузырьком) (Bubble Sort)
Определение:
Сортировка обменом (или пузырьковая сортировка) — это простой алгоритм, который многократно проходит по массиву, сравнивая соседние элементы и меняя их местами, если они расположены в неправильном порядке.
Анализ:
Алгоритм проходит по массиву, сравнивая соседние элементы и меняя их местами, если левый больше правого. Это "всплывание" самого большого элемента в конец.
Внешний цикл for выполняется n-1 раз.
Внутренний цикл for в худшем случае (когда массив отсортирован в обратном порядке) выполняется n-1, затем n-2, ..., раз.
Оптимизация с флагом swapped позволяет выйти из цикла раньше, если массив уже отсортирован.
Временная сложность:
Худший случай: O(n²) — массив отсортирован в обратном порядке.
Лучший случай: O(n) — массив уже отсортирован, срабатывает оптимизация.
Средний случай: O(n²)
Почему O(n²): В худшем случае, как и сортировка выбором, требует n*(n-1)/2 сравнений и потенциальных обменов.
Результат программы на JAVA:
	входные данные:{64, 34, 25, 12, 22, 11, 90}
	выходные данные:{11, 12, 22, 25, 34, 64, 90}
Заключение: Хотя сортировка пузырьком проста в понимании и реализации, её использование целесообразно только для небольших массивов или учебных целей.
Анализ алгоритма: Сортировка вставками (Insertion Sort)
Определение:
Сортировка вставками (Insertion Sort) — это алгоритм сортировки, в котором элементы входной последовательности просматриваются по одному, и каждый новый поступивший элемент размещается в подходящее место среди ранее упорядоченных элементов.
Анализ:
Алгоритм строит отсортированную часть списка, начиная с первого элемента. Каждый новый элемент вставляется в правильное место среди уже отсортированных.
Внешний цикл for проходит по n-1 элементам.
Внутренний цикл while в худшем случае (массив отсортирован в обратном порядке) может выполнить до i итераций на i-ой итерации внешнего цикла.
Временная сложность:
Худший случай: O(n²) — массив отсортирован в обратном порядке. Каждый элемент может потребовать i сдвигов.
Лучший случай: O(n) — массив уже отсортирован. Внутренний цикл while не выполняется.
Средний случай: O(n²)
Почему O(n²): В худшем случае общее количество сдвигов и сравнений составляет 1 + 2 + 3 + ... + (n-1) = n*(n-1)/2.
Результат программы на PYTHON:
	входные данные:[64, 34, 25, 12, 22, 11, 90]
	выходные данные:[11, 12, 22, 25, 34, 64, 90]
Заключение: Сортировка вставками хорошо подходит для малых массивов или почти отсортированных данных, обеспечивая достаточно высокую производительность в таких ситуациях. Однако для больших объёмов данных рекомендуется применять более эффективные методы типа быстрой сортировки или сортировки слиянием.
Анализ алгоритма: Сортировка слиянием (Merge Sort)
Определение:
Сортировка слиянием (Merge Sort) — алгоритм сортировки, который упорядочивает списки (или другие структуры данных, доступ к элементам которых можно получать только последовательно, например — потоки) в определённом порядке.
Анализ:
Алгоритм делит массив пополам рекурсивно до тех пор, пока не останутся подмассивы размером 1.
Затем он сливает эти подмассивы, создавая большие отсортированные подмассивы.
Это делается с помощью функции merge, которая объединяет два уже отсортированных подмассива.
Временная сложность: O(n log n)
Почему O(n log n):
Глубина рекурсии: Массив делится пополам на каждом уровне рекурсии. Количество уровней (глубина дерева рекурсии) составляет log n.
Работа на уровне: На каждом уровне рекурсии мы сливаем n элементов (все элементы массива). Функция merge для всего массива на одном уровне выполняет O(n) операций.
Общая сложность: log n уровней * n элементов на уровне = O(n log n).
Результат программы :
	входные данные:{8, 4, 2, 1}
	выходные данные:{1, 2, 4, 8}
Заключение: Таким образом, сортировка слиянием отлично подходит для обработки больших объемов данных благодаря своей стабильности и гарантированной средней и худшей временной сложности.
Анализ алгоритма: Сортировка Шелла (Shell Sort)
Определение:
Сортировка Шелла (Shell sort) — это алгоритм сортировки, являющийся усовершенствованным вариантом сортировки вставками. Идея метода Шелла состоит в сравнении элементов, стоящих не только рядом, но и на определённом расстоянии друг от друга.
Анализ:
Это модификация сортировки вставками. Она сначала сортирует элементы, находящиеся на определенном расстоянии (gap), затем уменьшает gap и повторяет процесс.
Выбор последовательности gap (например, n/2, n/4, ..., 1) влияет на производительность.
Временная сложность:
Зависит от выбранной последовательности gaps. Для последовательности, используемой в коде (n/2^k), сложность составляет O(n^(3/2)) или O(n log² n) в среднем случае, но может быть хуже.
В худшем случае (для некоторых последовательностей) может быть O(n²).
Для последовательности Кнута (gap = 3h + 1) сложность составляет O(n^(3/2)).
В целом, точная сложность часто выражается как O(n^p), где 1 < p <= 2.
Почему O(n^p): Алгоритм использует вложенные циклы, но внутренний цикл (по j) не всегда проходит n раз, как в пузырьке. Количество итераций зависит от gap. В среднем случае количество итераций внутреннего цикла растет медленнее, чем n, приводя к сложности между O(n) и O(n^2).
Результат программы:
	входные данные:{23, 12, 8, 15, 34}
	выходные данные:{8, 12, 15, 23, 34}
Заключение: Сортировка Шелла — хороший компромисс между производительностью и простотой реализации. Особенно эффективна на средних объёмах данных благодаря быстрому улучшению начальной расстановки элементов перед окончательной сортировкой. Рекомендуется применять её тогда, когда важен баланс между скоростью и потреблением ресурсов.
Анализ алгоритма: Быстрая сортировка (Quick Sort)
Определение:
Быстрая сортировка (Quick Sort) — это эффективный алгоритм сортировки, который использует принцип «разделяй и властвуй».
Анализ:
Выбирается опорный элемент. Массив перераспределяется так, что элементы, меньшие или равные опорному, оказываются слева от него, а большие — справа.
Затем рекурсивно сортируются левая и правая части.
Выбор опорного элемента критичен для производительности.
Временная сложность:
Средний случай: O(n log n) — если опорный элемент делит массив примерно пополам на каждом шаге.
Худший случай: O(n²) — если опорный элемент всегда является минимальным или максимальным (например, массив уже отсортирован, и опорный всегда последний). В этом случае дерево рекурсии имеет глубину n, а на каждом уровне выполняется n сравнений.
Лучший случай: O(n log n) — если опорный всегда делит массив ровно пополам.
Почему O(n log n) или O(n²):
Средний/Лучший: Глубина рекурсии log n, на каждом уровне n сравнений (в partition). n * log n.
Худший: Глубина рекурсии n, на каждом уровне до n, n-1, n-2, ... сравнений. n + (n-1) + ... + 1 = n(n+1)/2 ≈ O(n²).
Результат программы на PYTHON:
	входные данные:[3, 6, 8, 10, 1, 2, 1]
	выходные данные:[1, 1, 2, 3, 6, 8, 10]
Заключение: Быстрая сортировка — чрезвычайно эффективный алгоритм для большинства практических задач, обеспечивая высокую среднюю производительность. Её рекомендуют использовать везде, кроме случаев, когда гарантированная квадратичная сложность недопустима (например, при наличии заранее отсортированного массива).
Анализ алгоритма: Пирамидальная сортировка (Heap Sort)
Определение:
Пирамидальная сортировка (Heap Sort) — это алгоритм сортировки сравнением, который использует структуру данных двоичная куча.
Анализ:
Сначала строится max-heap (бинарное дерево, где родитель >= детей).
Затем максимальный элемент (корень) извлекается и помещается в конец массива. Куча уменьшается, и свойство heap восстанавливается для оставшейся части.
Временная сложность: O(n log n)
Почему O(n log n):
Построение кучи: build_max_heap выполняет heapify для n/2 узлов. Каждый вызов heapify может иметь глубину log n. В сумме это O(n) (доказывается математически, так как большинство узлов находятся ближе к листьям).
Сортировка: Цикл for выполняется n-1 раз. Внутри него вызывается heapify, который работает за O(log n) (глубина дерева). Итого n * O(log n) = O(n log n).
Общая сложность: O(n) (построение) + O(n log n) (сортировка) = O(n log n).
Результат программы на C++:
	входные данные:{12, 11, 13, 5, 6, 7}
	выходные данные:{5, 6, 7, 11, 12, 13}
Заключение: Пирамидальная сортировка демонстрирует отличную устойчивость по отношению к различным конфигурациям данных и обеспечивает стабильную производительность, что делает её предпочтительным вариантом для многих приложений, где требуется гарантированно быстрая сортировка большого объема данных.
Анализ алгоритма: Последовательный (линейный) поиск (Linear Search)
Определение:
Последовательный (линейный) поиск — это простой алгоритм, который поочередно проверяет каждый элемент в наборе данных, пока не будет найден искомый элемент или не будет пройден весь список.
Анализ:
Алгоритм последовательно просматривает элементы массива, сравнивая их с искомым значением.
Временная сложность:
Худший случай: O(n) — элемент находится в конце массива или отсутствует.
Лучший случай: O(1) — элемент находится в начале массива.
Средний случай: O(n/2) ≈ O(n)
Почему O(n): В худшем случае нужно проверить все n элементов.
Результат программы на PYTHON:
	входные данные:[10, 30, 40, 20, 50]
	выходные данные: Значение 30 найдено на позиции 2.
Заключение: Последовательный поиск удобен своей простотой и универсальностью, позволяя искать элементы в несортированных списках. Однако он теряет эффективность при большом объеме данных, поскольку приходится проверять большинство элементов массива для достижения результата.
Анализ алгоритма: Бинарный поиск (Binary Search)
Определение:
Бинарный поиск (Binary Search) — это алгоритм для поиска элемента в отсортированном массиве.
Анализ:
Алгоритм работает только с отсортированным массивом.
На каждом шаге область поиска уменьшается вдвое за счет сравнения с элементом в середине.
Временная сложность: O(log n)
Почему O(log n): На каждом шаге размер области поиска уменьшается примерно вдвое. Количество шагов, необходимых для сокращения n до 1, равно log₂ n.
Результат программы на C++:
	входные данные:{2, 3, 4, 10, 40}
	выходные данные: "Элемент найден на индексе 3."
Заключение: Бинарный поиск является эффективным инструментом для работы с отсортированными массивами, предлагая высокое быстродействие и низкую нагрузку на память. Он идеально подходит для ситуаций, когда нужно обеспечить быстрый доступ к данным в большом упорядоченном наборе.
Анализ алгоритма: Интерполирующий поиск (Interpolation Search)
Определение:
Интерполирующий поиск (интерполяционный поиск) — это алгоритм поиска значения в упорядоченном массиве чисел, который работает быстрее бинарного поиска при равномерном распределении данных.
Анализ:
Похож на бинарный поиск, но вместо деления пополам, предполагает позицию элемента на основе его значения и значений на границах, предполагая равномерное распределение.
Временная сложность:
Средний случай (равномерное распределение): O(log log n)
Худший случай (неравномерное распределение): O(n)
Почему O(log log n) или O(n):
Средний: При равномерном распределении, на каждом шаге размер области поиска уменьшается быстрее, чем в бинарном поиске. Количество шагов приблизительно равно log log n.
Худший: Если данные распределены неравномерно (например, большинство элементов сосредоточено в начале), pos может вычисляться близко к lo, и алгоритм может деградировать до линейного сканирования, проверяя каждый элемент по одному.
Результат программы:
	входные данные: {10, 12, 13, 16, 18, 19, 20, 21, 22, 23, 24, 33, 35, 42, 47}
	выходные данные: Индекс элемента 18: 4
Заключение: Интерполирующий поиск особенно хорош для больших массивов с равномерным распределением данных, демонстрируя превосходную производительность по сравнению с обычными методами поиска. Однако в случае нерегулярного распределения данных он уступает традиционным решениям вроде бинарного поиска.
Анализ алгоритма: Поиск по Фибоначчи (Fibonacci Search)
Определение:
Поиск методом Фибоначчи (Fibonacci Search) — это итеративный алгоритм для поиска экстремума (минимума или максимума) унимодальной функции на заданном интервале, а также метод поиска нужного значения в отсортированном массиве.
Анализ:
Использует числа Фибоначчи для определения точек разбиения массива, аналогично бинарному поиску (деление на части), но с разными пропорциями.
Временная сложность: O(log n)
Почему O(log n): Количество чисел Фибоначчи до n примерно равно log n. Каждая итерация цикла while уменьшает размер области поиска, используя меньшие числа Фибоначчи, что приводит к O(log n) итераций.
Результат программы:
	входные данные:[1, 3, 5, 7, 9, 11, 13]
	выходные данные:Элемент 7 найден на позиции 3
Заключение: Фибоначчи-поиск является эффективной альтернативой обычным методам поиска, обеспечивающей быстрые результаты в стандартных ситуациях. Однако, как и любые специализированные методы, он чувствителен к особенностям распределения данных и способен демонстрировать снижение производительности при неблагоприятном расположении элементов.
